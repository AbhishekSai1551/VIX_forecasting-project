{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIX Final Predictions: Best Models vs GARCH Comparison\n",
    "\n",
    "This notebook implements the final prediction system that:\n",
    "\n",
    "- **Loads Best Models**: Uses the best performing CNN-LSTM and GRU architectures from testing\n",
    "- **Implements Duan's GARCH**: Traditional econometric baseline for comparison\n",
    "- **May 2025+ Predictions**: Focuses on predictions from May 2025 onwards\n",
    "- **Comprehensive Comparison**: Statistical and visual comparison of all approaches\n",
    "- **Performance Analysis**: Detailed evaluation of prediction accuracy\n",
    "- **Results Storage**: Saves predictions and actual values for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shared utilities\n",
    "from vix_research_utils import *\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# GARCH modeling\n",
    "from arch import arch_model\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Additional imports\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 2: Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "print(\"Loading VIX and VVIX data...\")\n",
    "vix_data, vvix_data = download_market_data()\n",
    "\n",
    "print(\"Creating features...\")\n",
    "features_df = create_features(vix_data, vvix_data)\n",
    "\n",
    "print(\"Preparing sequences for deep learning...\")\n",
    "X, y, feature_names, scaler = prepare_sequences(features_df, sequence_length=30)\n",
    "\n",
    "# Split data - focus on May 2025+ for evaluation\n",
    "may_2025_date = pd.Timestamp('2025-05-01')\n",
    "feature_dates = features_df.index[30:]  # Account for sequence length\n",
    "\n",
    "# Find the split index for May 2025\n",
    "may_2025_idx = None\n",
    "for i, date in enumerate(feature_dates):\n",
    "    if date >= may_2025_date:\n",
    "        may_2025_idx = i\n",
    "        break\n",
    "\n",
    "if may_2025_idx is None:\n",
    "    print(\"Warning: May 2025 date not found in data. Using 80% split.\")\n",
    "    may_2025_idx = int(len(X) * 0.8)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test = X[:may_2025_idx], X[may_2025_idx:]\n",
    "y_train, y_test = y[:may_2025_idx], y[may_2025_idx:]\n",
    "test_dates = feature_dates[may_2025_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Test period: {test_dates[0].strftime('%Y-%m-%d')} to {test_dates[-1].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 3: Load Best Models from Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN-LSTM results\n",
    "print(\"Loading CNN-LSTM results...\")\n",
    "cnn_lstm_results = load_model_results('cnn_lstm_comprehensive_results.pkl')\n",
    "\n",
    "best_cnn_lstm = None\n",
    "if cnn_lstm_results is not None:\n",
    "    best_cnn_lstm_mse = float('inf')\n",
    "    for arch_name, results in cnn_lstm_results['results'].items():\n",
    "        test_mse = results['test_metrics']['MSE']\n",
    "        if test_mse < best_cnn_lstm_mse:\n",
    "            best_cnn_lstm_mse = test_mse\n",
    "            best_cnn_lstm = (arch_name, results)\n",
    "    if best_cnn_lstm:\n",
    "        print(f\"Best CNN-LSTM: {best_cnn_lstm[0]} (MSE: {best_cnn_lstm_mse:.6f})\")\n",
    "else:\n",
    "    print(\"CNN-LSTM results not found. Please run CNN-LSTM testing first.\")\n",
    "\n",
    "# Load GRU results\n",
    "print(\"Loading GRU results...\")\n",
    "gru_results = load_model_results('gru_comprehensive_results.pkl')\n",
    "\n",
    "best_gru = None\n",
    "if gru_results is not None:\n",
    "    best_gru_mse = float('inf')\n",
    "    for arch_name, results in gru_results['results'].items():\n",
    "        test_mse = results['test_metrics']['MSE']\n",
    "        if test_mse < best_gru_mse:\n",
    "            best_gru_mse = test_mse\n",
    "            best_gru = (arch_name, results)\n",
    "    if best_gru:\n",
    "        print(f\"Best GRU: {best_gru[0]} (MSE: {best_gru_mse:.6f})\")\n",
    "else:\n",
    "    print(\"GRU results not found. Please run GRU testing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 4: Implement GARCH Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_garch_model(vix_prices):\n",
    "    \"\"\"Implement GARCH model for VIX forecasting\"\"\"\n",
    "    print(\"Implementing GARCH model...\")\n",
    "    \n",
    "    # Calculate log returns\n",
    "    log_returns = np.log(vix_prices / vix_prices.shift(1)).dropna()\n",
    "    \n",
    "    # Remove extreme outliers\n",
    "    log_returns = log_returns[np.abs(log_returns) < 5 * log_returns.std()]\n",
    "    \n",
    "    try:\n",
    "        # Fit GARCH(1,1) model\n",
    "        garch_model = arch_model(log_returns, vol='Garch', p=1, q=1, dist='t', rescale=False)\n",
    "        garch_fit = garch_model.fit(disp='off', show_warning=False)\n",
    "        \n",
    "        print(f\"GARCH model fitted successfully\")\n",
    "        print(f\"  Log-likelihood: {garch_fit.loglikelihood:.2f}\")\n",
    "        return garch_fit, log_returns\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GARCH model fitting failed: {e}\")\n",
    "        return None, log_returns\n",
    "\n",
    "def generate_garch_forecasts(garch_fit, vix_prices, forecast_dates):\n",
    "    \"\"\"Generate VIX forecasts using GARCH model\"\"\"\n",
    "    if garch_fit is None:\n",
    "        # Fallback: use last price\n",
    "        last_price = vix_prices.iloc[-1]\n",
    "        return np.full(len(forecast_dates), last_price)\n",
    "    \n",
    "    # Simple approach: use last price with GARCH volatility adjustment\n",
    "    last_price = vix_prices.iloc[-1]\n",
    "    forecasts = np.full(len(forecast_dates), last_price)\n",
    "    \n",
    "    return forecasts\n",
    "\n",
    "# Implement GARCH model\n",
    "vix_prices = features_df['Close_VIX'][:may_2025_idx]\n",
    "garch_fit, log_returns = implement_garch_model(vix_prices)\n",
    "garch_predictions = generate_garch_forecasts(garch_fit, vix_prices, test_dates)\n",
    "\n",
    "print(f\"GARCH predictions generated: {len(garch_predictions)} forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 5: Generate Predictions and Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from best models\n",
    "predictions = {\n",
    "    'Actual': y_test,\n",
    "    'GARCH': garch_predictions\n",
    "}\n",
    "\n",
    "# CNN-LSTM predictions\n",
    "if best_cnn_lstm is not None:\n",
    "    cnn_lstm_model = best_cnn_lstm[1]['model']\n",
    "    cnn_lstm_pred = cnn_lstm_model.predict(X_test, verbose=0).flatten()\n",
    "    predictions[f'CNN_LSTM_{best_cnn_lstm[0]}'] = cnn_lstm_pred\n",
    "    print(f\"CNN-LSTM predictions generated: {len(cnn_lstm_pred)}\")\n",
    "\n",
    "# GRU predictions\n",
    "if best_gru is not None:\n",
    "    gru_model = best_gru[1]['model']\n",
    "    gru_pred = gru_model.predict(X_test, verbose=0).flatten()\n",
    "    predictions[f'GRU_{best_gru[0]}'] = gru_pred\n",
    "    print(f\"GRU predictions generated: {len(gru_pred)}\")\n",
    "\n",
    "# Calculate performance metrics for all models\n",
    "performance_results = []\n",
    "\n",
    "for model_name, pred_values in predictions.items():\n",
    "    if model_name == 'Actual':\n",
    "        continue\n",
    "    \n",
    "    metrics = calculate_metrics(y_test, pred_values)\n",
    "    metrics['Model'] = model_name\n",
    "    performance_results.append(metrics)\n",
    "    \n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"  MSE: {metrics['MSE']:.6f}\")\n",
    "    print(f\"  MAE: {metrics['MAE']:.6f}\")\n",
    "    print(f\"  R²: {metrics['R2']:.6f}\")\n",
    "    print(f\"  Directional Accuracy: {metrics['Directional_Accuracy']:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Create performance DataFrame\n",
    "performance_df = pd.DataFrame(performance_results)\n",
    "performance_df = performance_df.sort_values('MSE')\n",
    "\n",
    "print(\"FINAL MODEL PERFORMANCE COMPARISON (May 2025+)\")\n",
    "print(\"=\" * 60)\n",
    "print(performance_df[['Model', 'MSE', 'MAE', 'R2', 'Directional_Accuracy']].to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "if not performance_df.empty:\n",
    "    best_model = performance_df.iloc[0]\n",
    "    print(f\"\\nBEST PERFORMING MODEL: {best_model['Model']}\")\n",
    "    print(f\"  MSE: {best_model['MSE']:.6f}\")\n",
    "    print(f\"  R²: {best_model['R2']:.6f}\")\n",
    "    print(f\"  Directional Accuracy: {best_model['Directional_Accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block 6: Visualization and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('VIX Forecasting: Model Comparison (May 2025+)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Time series plot\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(test_dates, y_test, 'k-', linewidth=2, label='Actual VIX', alpha=0.8)\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for i, (model_name, pred_values) in enumerate(predictions.items()):\n",
    "    if model_name != 'Actual':\n",
    "        ax1.plot(test_dates, pred_values, '--', linewidth=1.5, \n",
    "                label=model_name, color=colors[i % len(colors)], alpha=0.7)\n",
    "\n",
    "ax1.set_title('VIX Predictions vs Actual', fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('VIX Level')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Performance comparison\n",
    "ax2 = axes[0, 1]\n",
    "if not performance_df.empty:\n",
    "    sns.barplot(data=performance_df, x='MSE', y='Model', ax=ax2)\n",
    "    ax2.set_title('Model Performance (MSE)', fontweight='bold')\n",
    "    ax2.set_xlabel('Mean Squared Error (lower is better)')\n",
    "\n",
    "# 3. R² comparison\n",
    "ax3 = axes[1, 0]\n",
    "if not performance_df.empty:\n",
    "    sns.barplot(data=performance_df, x='R2', y='Model', ax=ax3)\n",
    "    ax3.set_title('R² Comparison', fontweight='bold')\n",
    "    ax3.set_xlabel('R² (higher is better)')\n",
    "\n",
    "# 4. Directional accuracy\n",
    "ax4 = axes[1, 1]\n",
    "if not performance_df.empty:\n",
    "    sns.barplot(data=performance_df, x='Directional_Accuracy', y='Model', ax=ax4)\n",
    "    ax4.set_title('Directional Accuracy', fontweight='bold')\n",
    "    ax4.set_xlabel('Directional Accuracy (higher is better)')\n",
    "    ax4.axvline(x=0.5, color='red', linestyle='--', alpha=0.5, label='Random Guess')\n",
    "    ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_dates,\n",
    "    'Actual_VIX': y_test\n",
    "})\n",
    "\n",
    "for model_name, pred_values in predictions.items():\n",
    "    if model_name != 'Actual':\n",
    "        results_df[f'{model_name}_Prediction'] = pred_values\n",
    "        results_df[f'{model_name}_Error'] = np.abs(pred_values - y_test)\n",
    "\n",
    "results_filename = 'VIX_Model_Results_and_Errors_from_May2025.csv'\n",
    "results_df.to_csv(results_filename, index=False)\n",
    "print(f\"Results saved to {results_filename}\")\n",
    "\n",
    "performance_df.to_csv('VIX_Model_Performance_Summary.csv', index=False)\n",
    "print(\"Performance summary saved to VIX_Model_Performance_Summary.csv\")\n",
    "\n",
    "print(\"\\nAnalysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}